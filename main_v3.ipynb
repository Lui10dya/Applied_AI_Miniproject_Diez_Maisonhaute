{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1L1T13hDbWdb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  class_label                                              array  \\\n",
      "0           0            0  [[[211 208 200]\\n  [211 208 200]\\n  [213 210 2...   \n",
      "1           1            3  [[[199 116  47]\\n  [209 121  48]\\n  [221 125  ...   \n",
      "2           2            2  [[[108 101 104]\\n  [107 100 103]\\n  [102  95  ...   \n",
      "3           3            3  [[[255 255 255]\\n  [255 255 255]\\n  [255 255 2...   \n",
      "4           4            0  [[[  4   7   0]\\n  [  4   7   0]\\n  [  4   6  ...   \n",
      "\n",
      "                                            img_path  \n",
      "0  ../input/affectnetsample/train_class/class001/...  \n",
      "1  ../input/affectnetsample/train_class/class004/...  \n",
      "2  ../input/affectnetsample/train_class/class003/...  \n",
      "3  ../input/affectnetsample/train_class/class004/...  \n",
      "4  ../input/affectnetsample/train_class/class001/...  \n"
     ]
    }
   ],
   "source": [
    "#Load the 2nd dataset\n",
    "import pandas as pd\n",
    "\n",
    "#The data set : https://www.kaggle.com/datasets/sarabhian/affectnet-helper\n",
    "#Rename the folder as faceEmotion_dataset_v3\n",
    "\n",
    "# read the CSV files\n",
    "df_train = pd.read_csv(\"faceEmotion_dataset_v3/train.csv\")\n",
    "df_test = pd.read_csv(\"faceEmotion_dataset_v3/val.csv\")\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "# print the first few rows of the DataFrame\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[211 208 200],[211 208 200],[213 210 202] ... [225 222 214],[226 224 215],[227 224 216]],[[212 209 201],[210 207 199],[217 214 207] ... [225 222 214],[225 222 214],[225 222 214]],[[212 209 201],[211 208 200],[216 213 205] ... [225 222 215],[223 220 213],[223 220 212]] ... [[137 162 166],[136 158 163],[134 154 159] ... [ 20 21 12],[ 23 24 15],[ 25 26 17]],[[131 155 161],[132 156 162],[133 154 160] ... [ 21 22 13],[ 22 23 14],[ 21 22 13]],[[128 152 158],[131 155 161],[132 156 162] ... [ 26 27 18],[ 23 24 15],[ 21 22 13]]]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# string representation of a list of 3D images\n",
    "images_string = df_train[\"array\"]\n",
    "\n",
    "# remove extra whitespace and newline characters from the string\n",
    "# images_string = images_string.apply(str.strip)\n",
    "# images_string = images_string.replace('\\n', '').replace(' ', '')\n",
    "# images_string = images_string.apply(lambda elem : elem.replace('\\n', '').replace('  ', ' ').replace(' ', ',').replace('[,', '[').replace(\",,\", \",\"))\n",
    "images_string = images_string.apply(lambda elem : elem.replace('\\n', '').replace('  ', ' ').replace('] [', '],['))\n",
    "# print(test2)\n",
    "print(images_string[0])\n",
    "# print(images_string[0].split(','))\n",
    "\n",
    "\n",
    "# # parse the string using ast.literal_eval()\n",
    "# images_list = images_string.apply(ast.literal_eval)\n",
    "\n",
    "# # convert each element of the list to a NumPy array\n",
    "# images = images_list.apply(lambda x: np.array(x))\n",
    "\n",
    "# # print the images\n",
    "# print(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[211 208 200]pp  [211 208 200]pp  [213 210 202]pp  ...pp  [225 222 214]pp  [226 224 215]pp  [227 224 216]]pppp [[212 209 201]pp  [210 207 199]pp  [217 214 207]pp  ...pp  [225 222 214]pp  [225 222 214]pp  [225 222 214]]pppp [[212 209 201]pp  [211 208 200]pp  [216 213 205]pp  ...pp  [225 222 215]pp  [223 220 213]pp  [223 220 212]]pppp ...pppp [[137 162 166]pp  [136 158 163]pp  [134 154 159]pp  ...pp  [ 20  21  12]pp  [ 23  24  15]pp  [ 25  26  17]]pppp [[131 155 161]pp  [132 156 162]pp  [133 154 160]pp  ...pp  [ 21  22  13]pp  [ 22  23  14]pp  [ 21  22  13]]pppp [[128 152 158]pp  [131 155 161]pp  [132 156 162]pp  ...pp  [ 26  27  18]pp  [ 23  24  15]pp  [ 21  22  13]]\n",
      "\n",
      "['[[211 208 200]pp  [211 208 200]pp  [213 210 202]pp  ...pp  [225 222 214]pp  [226 224 215]pp  [227 224 216]]', '[[212 209 201]pp  [210 207 199]pp  [217 214 207]pp  ...pp  [225 222 214]pp  [225 222 214]pp  [225 222 214]]', '[[212 209 201]pp  [211 208 200]pp  [216 213 205]pp  ...pp  [225 222 215]pp  [223 220 213]pp  [223 220 212]]', '...', '[[137 162 166]pp  [136 158 163]pp  [134 154 159]pp  ...pp  [ 20  21  12]pp  [ 23  24  15]pp  [ 25  26  17]]', '[[131 155 161]pp  [132 156 162]pp  [133 154 160]pp  ...pp  [ 21  22  13]pp  [ 22  23  14]pp  [ 21  22  13]]', '[[128 152 158]pp  [131 155 161]pp  [132 156 162]pp  ...pp  [ 26  27  18]pp  [ 23  24  15]pp  [ 21  22  13]]']\n",
      "\n",
      "[[211 208 200]pp  [211 208 200]pp  [213 210 202]pp  ...pp  [225 222 214]pp  [226 224 215]pp  [227 224 216]]\n",
      "[211 208 200]pp  [211 208 200]pp  [213 210 202]pp  ...pp  [225 222 214]pp  [226 224 215]pp  [227 224 216]\n",
      "['[211 208 200]', '[211 208 200]', '[213 210 202]', '...', '[225 222 214]', '[226 224 215]', '[227 224 216]']\n",
      "[[212 209 201]pp  [210 207 199]pp  [217 214 207]pp  ...pp  [225 222 214]pp  [225 222 214]pp  [225 222 214]]\n",
      "[212 209 201]pp  [210 207 199]pp  [217 214 207]pp  ...pp  [225 222 214]pp  [225 222 214]pp  [225 222 214]\n",
      "['[212 209 201]', '[210 207 199]', '[217 214 207]', '...', '[225 222 214]', '[225 222 214]', '[225 222 214]']\n",
      "[[212 209 201]pp  [211 208 200]pp  [216 213 205]pp  ...pp  [225 222 215]pp  [223 220 213]pp  [223 220 212]]\n",
      "[212 209 201]pp  [211 208 200]pp  [216 213 205]pp  ...pp  [225 222 215]pp  [223 220 213]pp  [223 220 212]\n",
      "['[212 209 201]', '[211 208 200]', '[216 213 205]', '...', '[225 222 215]', '[223 220 213]', '[223 220 212]']\n",
      "...\n",
      ".\n",
      "['.']\n",
      "[[137 162 166]pp  [136 158 163]pp  [134 154 159]pp  ...pp  [ 20  21  12]pp  [ 23  24  15]pp  [ 25  26  17]]\n",
      "[137 162 166]pp  [136 158 163]pp  [134 154 159]pp  ...pp  [ 20  21  12]pp  [ 23  24  15]pp  [ 25  26  17]\n",
      "['[137 162 166]', '[136 158 163]', '[134 154 159]', '...', '[ 20  21  12]', '[ 23  24  15]', '[ 25  26  17]']\n",
      "[[131 155 161]pp  [132 156 162]pp  [133 154 160]pp  ...pp  [ 21  22  13]pp  [ 22  23  14]pp  [ 21  22  13]]\n",
      "[131 155 161]pp  [132 156 162]pp  [133 154 160]pp  ...pp  [ 21  22  13]pp  [ 22  23  14]pp  [ 21  22  13]\n",
      "['[131 155 161]', '[132 156 162]', '[133 154 160]', '...', '[ 21  22  13]', '[ 22  23  14]', '[ 21  22  13]']\n",
      "[[128 152 158]pp  [131 155 161]pp  [132 156 162]pp  ...pp  [ 26  27  18]pp  [ 23  24  15]pp  [ 21  22  13]]\n",
      "[128 152 158]pp  [131 155 161]pp  [132 156 162]pp  ...pp  [ 26  27  18]pp  [ 23  24  15]pp  [ 21  22  13]\n",
      "['[128 152 158]', '[131 155 161]', '[132 156 162]', '...', '[ 26  27  18]', '[ 23  24  15]', '[ 21  22  13]']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataArray(images_string):\n",
    "    for image_str in (images_string):\n",
    "        # images_string = images_string.apply(lambda elem : elem.replace('\\n', '').replace('  ', ' ').replace('] [', '],['))\n",
    "        # print(image_str.replace('\\n', 'pppp'))\n",
    "        image_str = image_str.replace('\\n', 'pp')\n",
    "        image_str_interieur = image_str[1:len(image_str) - 1]\n",
    "\n",
    "        # image_str_interieur_interieurs = []\n",
    "        # compteur_crochet = 0\n",
    "        # for lettre in image_str_interieur:\n",
    "        #     if(lettre == \"[\") :\n",
    "        #         compteur_crochet +=1\n",
    "        #     elif(lettre == \"]\") :\n",
    "        #         compteur_crochet -=1\n",
    "        \n",
    "        # print(\"fin\")\n",
    "        print(image_str_interieur)\n",
    "        print()\n",
    "        image_str_interieur_splited = image_str_interieur.split('pppp ')\n",
    "        print(image_str_interieur_splited)\n",
    "        print()\n",
    "\n",
    "        image_interieur_list = []\n",
    "        for elem in image_str_interieur_splited :\n",
    "            \n",
    "            image_str_interieur_splited_interieur = elem[1:len(elem) - 1]\n",
    "            print(elem)\n",
    "            print(image_str_interieur_splited_interieur)\n",
    "            print(image_str_interieur_splited_interieur.split(\"pp  \"))\n",
    "\n",
    "        #     print(\"fin\")\n",
    "            # image_interieur_list.append(elem.split('pp'))\n",
    "        # print(image_interieur_list)\n",
    "preprocess_dataArray(df_train[\"array\"][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_string_to_arrayImages_withColor(L, sizeX=48, sizeY=48):\n",
    "\n",
    "    Images_Dataset = []\n",
    "    for k in range(L.index[0], L.index[-1] + 1):\n",
    "        # split the string into a list of strings\n",
    "        # lst = df[\" pixels\"][k].split()\n",
    "        lst = L[k].split()\n",
    "\n",
    "        # convert the strings to integers using map() and a lambda function\n",
    "        lst = list(map(lambda x: int(x), lst))\n",
    "\n",
    "        Images_Dataset.append(lst)\n",
    "    Images_Dataset = np.array(Images_Dataset)\n",
    "    Images_Dataset = Images_Dataset.reshape(Images_Dataset.shape[0], sizeX , sizeY)\n",
    "\n",
    "    return Images_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48)\n",
      "(7178, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "#Proprocess dataset and get X_train and X_test\n",
    "X_train = list_string_to_arrayImages(df_train[\" pixels\"])\n",
    "X_test = list_string_to_arrayImages(df_test[\" pixels\"])\n",
    "\n",
    "print((X_train).shape)\n",
    "print((X_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get y_train and y_test\n",
    "Labels_train = list(df_train[\"emotion\"])\n",
    "Labels_test = list(df_test[\"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "898/898 [==============================] - 59s 64ms/step - loss: 8.6876 - accuracy: 0.2584\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 34s 38ms/step - loss: 1.6639 - accuracy: 0.3553\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 32s 35ms/step - loss: 1.4980 - accuracy: 0.4287\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 32s 36ms/step - loss: 1.3552 - accuracy: 0.4852\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 33s 36ms/step - loss: 1.2626 - accuracy: 0.5231\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 31s 34ms/step - loss: 1.1939 - accuracy: 0.5527\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 32s 36ms/step - loss: 1.1195 - accuracy: 0.5874\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1.0601 - accuracy: 0.6088\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1.0669 - accuracy: 0.6051\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1.0106 - accuracy: 0.6279\n",
      "225/225 [==============================] - 3s 13ms/step\n",
      "Accuracy: 0.3647255502925606\n"
     ]
    }
   ],
   "source": [
    "#change the shape of the object labels\n",
    "y_train = to_categorical(Labels_train, num_classes) \n",
    "y_test = to_categorical(Labels_test, num_classes) \n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the predictions\n",
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fbef96a433aec4ee8be3bee9000d8ceb0ccbbbdc08053ad2b2121fec2f6d456"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
