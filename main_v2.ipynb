{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1L1T13hDbWdb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion     Usage                                             pixels\n",
      "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
      "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
      "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
      "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
      "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n"
     ]
    }
   ],
   "source": [
    "#Load the 2nd dataset\n",
    "import pandas as pd\n",
    "\n",
    "#The data set : https://www.kaggle.com/datasets/debanga/facial-expression-recognition-challenge?resource=download\n",
    "#Rename the folder as faceEmotion_dataset_v2\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv(\"faceEmotion_dataset_v2/icml_face_data.csv/icml_face_data.csv\")\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "# print the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split between training and test\n",
    "maskTraining = df[\" Usage\"] == \"Training\"\n",
    "maskTest = [not elem for elem in maskTraining]\n",
    "\n",
    "df_train = df.loc[maskTraining]\n",
    "df_test = df.loc[maskTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_string_to_arrayImages(L, sizeX=48, sizeY=48):\n",
    "\n",
    "    Images_Dataset = []\n",
    "    for k in range(L.index[0], L.index[-1] + 1):\n",
    "        # split the string into a list of strings\n",
    "        # lst = df[\" pixels\"][k].split()\n",
    "        lst = L[k].split()\n",
    "\n",
    "        # convert the strings to integers using map() and a lambda function\n",
    "        lst = list(map(lambda x: int(x), lst))\n",
    "\n",
    "        Images_Dataset.append(lst)\n",
    "    Images_Dataset = np.array(Images_Dataset)\n",
    "    Images_Dataset = Images_Dataset.reshape(Images_Dataset.shape[0], sizeX , sizeY)\n",
    "    Images_Dataset = Images_Dataset.astype('float32')\n",
    "    Images_Dataset /= 255\n",
    "    return Images_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48)\n",
      "(7178, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "#Proprocess dataset and get X_train and X_test\n",
    "X_train = list_string_to_arrayImages(df_train[\" pixels\"])\n",
    "X_test = list_string_to_arrayImages(df_test[\" pixels\"])\n",
    "\n",
    "print((X_train).shape)\n",
    "print((X_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get y_train and y_test\n",
    "Labels_train = list(df_train[\"emotion\"])\n",
    "Labels_test = list(df_test[\"emotion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "898/898 [==============================] - 85s 93ms/step - loss: 1.6230 - accuracy: 0.3700\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 73s 81ms/step - loss: 1.4489 - accuracy: 0.4520\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 60s 67ms/step - loss: 1.3662 - accuracy: 0.4911\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 47s 52ms/step - loss: 1.3074 - accuracy: 0.5112\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 31s 35ms/step - loss: 1.2569 - accuracy: 0.5329\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 33s 36ms/step - loss: 1.2117 - accuracy: 0.5516\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 38s 42ms/step - loss: 1.1702 - accuracy: 0.5680\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 31s 34ms/step - loss: 1.1300 - accuracy: 0.5822\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 30s 33ms/step - loss: 1.0948 - accuracy: 0.5975\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 30s 34ms/step - loss: 1.0571 - accuracy: 0.6148\n",
      "225/225 [==============================] - 3s 13ms/step\n",
      "Accuracy: 0.47924212872666483\n"
     ]
    }
   ],
   "source": [
    "#change the shape of the object labels\n",
    "y_train = to_categorical(Labels_train, num_classes) \n",
    "y_test = to_categorical(Labels_test, num_classes) \n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy of the predictions\n",
    "accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[39m# calculate the precision, recall, and F1 score\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m precision \u001b[39m=\u001b[39m precision_score(np\u001b[39m.\u001b[39;49margmax(y_test, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), np\u001b[39m.\u001b[39;49margmax(predictions, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m      5\u001b[0m recall \u001b[39m=\u001b[39m recall_score(np\u001b[39m.\u001b[39margmax(y_test, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m      6\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(np\u001b[39m.\u001b[39margmax(y_test, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Tiziano\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1769\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[0;32m   1641\u001b[0m     y_true,\n\u001b[0;32m   1642\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1648\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1649\u001b[0m ):\n\u001b[0;32m   1650\u001b[0m     \u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m \n\u001b[0;32m   1652\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1767\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1768\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1769\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1770\u001b[0m         y_true,\n\u001b[0;32m   1771\u001b[0m         y_pred,\n\u001b[0;32m   1772\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1773\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1774\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1775\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1776\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1777\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1778\u001b[0m     )\n\u001b[0;32m   1779\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\Tiziano\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1556\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1555\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1556\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1558\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Tiziano\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1373\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1374\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1375\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1376\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1377\u001b[0m         )\n\u001b[0;32m   1378\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[0;32m   1379\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1380\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1381\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1385\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# calculate the precision, recall, and F1 score\n",
    "precision = precision_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "recall = recall_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "f1 = f1_score(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1))\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fbef96a433aec4ee8be3bee9000d8ceb0ccbbbdc08053ad2b2121fec2f6d456"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
